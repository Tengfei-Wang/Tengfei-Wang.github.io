<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title> Tengfei WANG  </title>
  
  <meta name="author" content="Jon Barron">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Tengfei WANG </name>  <br> <br>
              </p>
              <p style="font-family:verdana"> I am a fourth-year Ph.D. student at the Hong Kong University of Science and Technology (<a href="https://hkust.edu.hk/?cn=1">HKUST</a>), advised by <a href="https://cqf.io">Qifeng Chen</a>. 
                I am currently a research intern at Microsoft Research Asia (MSRA). I was a research intern at Tencent AI Lab.
                <br> I'm interested in AI-based visual content creation such as image synthesis and editing, and 
                3D content creation and rendering.  
              </p>
 
 
              <p style="text-align:center">
                <a href="mailto:tengfeiwang12@gmail.com"> Email</a> &nbsp/&nbsp
                <a href="https://github.com/Tengfei-Wang"> Github</a> &nbsp/&nbsp 
                <a href="https://scholar.google.com/citations?user=HjpeWKcAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/in/tengfei-wang-836540213/">Linked In</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
             <img style="width:100%;max-width:100%" alt="profile photo" src="images/profile-pic.png" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
                                                                                                                          
                                                                                                                          
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
                <tbody>
                  <tr>
                    <td>
                      <heading>News</heading>
                      <p>
                      <ul>
                        <li>News (Fed  2023): Two papers accepted to CVPR 2023.</li>
                        <li>News (Mar  2022): One paper accepted to CVPR 2022.</li>
                        <li>News (Dec  2021): One paper accepted to AAAI 2022.</li>
                        <li>News (Jul  2021): Two papers accepted to ICCV 2021.</li>
                        <li>News (Mar 2021): One paper accepted to CVPR 2021.</li>
                        
                      </ul>
                      </p>
                    </td>
                  </tr>
                </tbody>
        </tbody></table>
 
        <heading>Publications</heading>
        <p> (* indicates joint first authors) </p>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

            <tr onmouseout="Rodin_stop()" onmouseover="Rodin_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
    
              <div class="one">
                <div class="two" id='Rodin_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/rodin.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/rodin.jpg' width="160">
              </div>
              
              <script type="text/javascript">
                function Rodin_start() {
                  document.getElementById('Rodin_image').style.opacity = "1";
                }

                function Rodin_stop() {
                  document.getElementById('Rodin_image').style.opacity = "0";
                }
                Rodin_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle> Rodin: A Generative Model for Sculpting 3D Digital Avatars Using Diffusion  </papertitle>
              </a>
              <br>
              <strong>  Tengfei Wang* </strong>,  Bo Zhang*, Ting Zhang, Shuyang Gu,  Jianmin Bao, Tadas Baltrusaitis, Jingjing Shen, Dong Chen, Fang Wen, Qifeng Chen, Baining Guo
              <br>
              <em> CVPR</em>, 2023   
              <br>
              <a href="https://arxiv.org/abs/2212.06135">arxiv</a> / 
              <a href="https://3d-avatar-diffusion.microsoft.com/">code</a> /  
              <a href="https://3d-avatar-diffusion.microsoft.com/">project website</a> /  
              <a href="https://www.youtube.com/watch?v=KW_EXWMjS4c">video</a> /
              <p></p>
              <p style="color:red"> 3D diffusion models for automatically generating high-quality 3D digital avatars represented as a neural radiance field. 
             </p>
            </td>
          </tr>  

            <tr onmouseout="SPI_stop()" onmouseover="SPI_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
    
              <div class="one">
                <div class="two" id='SPI_image'>
                  <img src='images/SPI_after.png' width="160"></div>
                <img src='images/SPI_before.png' width="160">
              </div>
              
              <script type="text/javascript">
                function SPI_start() {
                  document.getElementById('SPI_image').style.opacity = "1";
                }

                function SPI_stop() {
                  document.getElementById('SPI_image').style.opacity = "0";
                }
                SPI_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle> 3D GAN Inversion with Facial Symmetry Prior  </papertitle>
              </a>
              <br>
              Fei Yin, Yong Zhang, Xuan Wang, <strong> Tengfei Wang </strong>, Xiaoyu Li, Yuan Gong, Yanbo Fan, Xiaodong Cun, Ying Shan, Cengiz Oztireli, Yujiu Yang
              <br>
              <em> CVPR</em>, 2023   
              <br>
              <a href="https://arxiv.org/pdf/2211.16927">arxiv</a> / 
              <a href="https://github.com/FeiiYin/SPI/">code</a> /  
              <a href="https://feiiyin.github.io/SPI/">project website</a> /  
              <p></p>
              <p style="color:red">   
             </p>
            </td>
          </tr>  

            <tr onmouseout="PITI_stop()" onmouseover="PITI_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='PITI_image'>
                  <img src='images/PITI_after.png' width="160"></div>
                <img src='images/PITI_before.png' width="160">
              </div>
              <script type="text/javascript">
                function PITI_start() {
                  document.getElementById('PITI_image').style.opacity = "1";
                }

                function PITI_stop() {
                  document.getElementById('PITI_image').style.opacity = "0";
                }
                PITI_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle> Pretraining is All You Need for Image-to-Image Translation  </papertitle>
              </a>
              <br>
              <strong>  Tengfei Wang </strong>, Ting Zhang, Bo Zhang, Hao Ouyang,  Dong Chen, Qifeng Chen, Fang Wen 
              <br>
              <em> preprint</em>, 2022   
              <br>
              <a href="https://arxiv.org/abs/2205.12952">arxiv</a> / 
              <a href="https://github.com/PITI-Synthesis/PITI">code</a> /  
              <a href="https://tengfei-wang.github.io/PITI/index.html">project website</a> / 
              <a href="https://huggingface.co/spaces/tfwang/PITI-Synthesis">online demo</a> / 
              <p></p>
              <p style="color:red"> A simple and universal framework that brings the power of the pretraining to various image-to-image translation tasks.
             </p>
            </td>
          </tr>               
          

            <tr onmouseout="hfgi_21_stop()" onmouseover="hfgi_21_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='hfgi_21_image'>
                  <img src='images/hfgi_21_after.gif' width="160"></div>
                <img src='images/hfgi_21_before.jpg' width="160">
              </div>
              <script type="text/javascript">
                function hfgi_21_start() {
                  document.getElementById('hfgi_21_image').style.opacity = "1";
                }

                function hfgi_21_stop() {
                  document.getElementById('hfgi_21_image').style.opacity = "0";
                }
                hfgi_21_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle> High-Fidelity GAN Inversion for Image Attribute Editing  </papertitle>
              </a>
              <br>
              <strong>  Tengfei Wang </strong>, Yong Zhang, Yanbo Fan,  Jue Wang, Qifeng Chen 
              <br>
              <em> CVPR </em>, 2022   
              <br>
              <a href="https://arxiv.org/abs/2109.06590">arxiv</a> / 
              <a href="https://github.com/Tengfei-Wang/HFGI">code</a> /  
              <a href="https://tengfei-wang.github.io/HFGI/">project website</a> /
              <a href="https://www.youtube.com/watch?v=_CXk4LjoKP8">video</a> /  
              <a href="https://colab.research.google.com/github/Tengfei-Wang/HFGI/blob/main/HFGI_playground.ipynb">colab</a> / 
              <a href="https://replicate.com/tengfei-wang/hfgi">online demo</a> / 
              <p></p>
              <p style="color:red"> A novel GAN inversion framework for high-fidelity image and video editng.
             </p>
            </td>
          </tr>     

   
     <tr onmouseout="restore_21_stop()" onmouseover="restore_21_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='restore_21_image'>
                  <img src='images/restore_21_after.jpg' width="160"></div>
                <img src='images/restore_21_before.jpg' width="160">
              </div>
              <script type="text/javascript">
                function restore_21_start() {
                  document.getElementById('restore_21_image').style.opacity = "1";
                }

                function restore_21_stop() {
                  document.getElementById('restore_21_image').style.opacity = "0";
                }
                restore_21_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle> Restorable Image Operators with Quasi-Invertible Networks  </papertitle>
              </a>
              <br>
              Hao Ouyang*, <strong>  Tengfei Wang* </strong>, Qifeng Chen 
              <br>
              <em> AAAI </em>, 2022   
              <br>
              <a href="https://www.aaai.org/AAAI22Papers/AAAI-2467.OuyangHao.pdf">arxiv</a> / 
              <a href="https://github.com/ken-ouyang/IVOP">code</a> / 
              <a href="https://tengfei-wang.github.io/Restorable-Image-Operator/">project website</a> /
              <a href="https://www.youtube.com/watch?v=iB7k7jDa9Kg">video</a> /  
              <p></p>
              <p style="color:red"> A general and unified framework for versatile invertible image processing operators.
             </p>       
            </td>
          </tr>     


              <tr onmouseout="sr_iccv21_stop()" onmouseover="sr_iccv21_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='sr_iccv21_image'>
                  <img src='images/sr_iccv21_after.jpg' width="160"></div>
                <img src='images/sr_iccv21_before.jpg' width="160">
              </div>
              <script type="text/javascript">
                function sr_iccv21_start() {
                  document.getElementById('sr_iccv21_image').style.opacity = "1";
                }

                function sr_iccv21_stop() {
                  document.getElementById('sr_iccv21_image').style.opacity = "0";
                }
                sr_iccv21_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle> Dual-Camera Super-Resolution with Aligned Attention Modules  </papertitle>
              </a>
              <br>
              <strong>  Tengfei Wang *</strong>, Jiaxin Xie *, Wenxiu Sun,  Qiong Yan, Qifeng Chen 
              <br>
              <em>ICCV </em>, 2021  <strong style="color:red"> (Oral Presentation)</strong>
              <br>
              <a href="https://arxiv.org/abs/2109.01349">arxiv</a> / 
              <a href="https://github.com/Tengfei-Wang/DCSR">code</a> /  
              <a href="https://tengfei-wang.github.io/Dual-Camera-SR/index.html">project website</a> /
              <a href="https://github.com/Tengfei-Wang/DCSR">dataset</a> /  
              <a href="https://youtu.be/5TiUfAcNvuw">video</a> / 
              <p></p>
              <p style="color:red"> First real-world dual-camera super-resolution approach. <br>
               A new high-quality dataset for dual-camera zoom (telephoto and wide-angle). </p>
            </td>
          </tr>     


          
          
           <tr onmouseout="inpainting_iccv21_stop()" onmouseover="inpainting_iccv21_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='inpainting_iccv21_image'>
                  <img src='images/inpainting_iccv21_after.jpg' width="160"></div>
                <img src='images/inpainting_iccv21_before.jpg' width="160">
              </div>
              <script type="text/javascript">
                function inpainting_iccv21_start() {
                  document.getElementById('inpainting_iccv21_image').style.opacity = "1";
                }

                function inpainting_iccv21_stop() {
                  document.getElementById('inpainting_iccv21_image').style.opacity = "0";
                }
                inpainting_iccv21_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle> Internal Video Inpainting by Implicit Long-range Propagation </papertitle>
              </a>
              <br>
              Hao Ouyang*,  <strong> Tengfei Wang*</strong>,  Qifeng Chen 
              <br>
              <em>ICCV </em>, 2021  
              <br>
              <a href="https://arxiv.org/abs/2108.01912">arxiv</a> / 
              <a href="https://github.com/Tengfei-Wang/Implicit-Internal-Video-Inpainting">code</a> / 
              <a href="https://tengfei-wang.github.io/Implicit-Internal-Video-Inpainting/index.html">project website</a> /
              <a href="https://github.com/Tengfei-Wang/Annotated-4K-Videos">dataset</a> /  
              <a href="https://www.youtube.com/watch?v=VlDSJtmBqBs">video</a> /  
              <p></p>
              <p style="color:red"> A simple yet effective video inpainting method for  videos from arbitrary domain. 
                <br> No training set and pretrained models are needed.  </p>
            </td>
          </tr>           
          
 
          <tr onmouseout="inpainting_cvpr21_stop()" onmouseover="inpainting_cvpr21_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='inpainting_cvpr21_image'>
                  <img src='images/inpainting_cvpr21_after.jpg' width="160"></div>
                <img src='images/inpainting_cvpr21_before.jpg' width="160">
              </div>
              <script type="text/javascript">
                function inpainting_cvpr21_start() {
                  document.getElementById('inpainting_cvpr21_image').style.opacity = "1";
                }

                function inpainting_cvpr21_stop() {
                  document.getElementById('inpainting_cvpr21_image').style.opacity = "0";
                }
                inpainting_cvpr21_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle> Image Inpainting with External-internal Learning and Monochromic Bottleneck  </papertitle>
              </a>
              <br>
              <strong>Tengfei Wang *</strong>, Hao Ouyang *, Qifeng Chen 
              <br>
              <em>CVPR </em>, 2021  
              <br>
              <a href="https://arxiv.org/abs/2104.09068">arxiv</a> / 
              <a href="https://github.com/Tengfei-Wang/external-internal-inpainting">code</a> / 
              <a href="https://tengfei-wang.github.io/EII/index.html">project website</a> /
              <a href="https://youtu.be/JFBEL7qPFVc">video</a> /
              <p></p>
              <p style="color:red"> A novel internal-learning method for guided image colorization  </p>
            </td>
          </tr>  

        </tbody></table>


<!--          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Teaching</heading>
                <ul>
                  <li>Assistant Coach of <a href="https://www.cse.ust.hk/acm/"> HKUST ACM-ICPC Teams </a> (2019 Fall, 2020 Spring, 2020 Fall, 2021 Spring, 2021 Fall) </li>
                  <li>COMP 3071: Honors Competitive Programming</li>          
                </ul>
           </td>
          </tr>
        </tbody></table>  -->

         <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Services</heading>
                <ul>
                  Program Committee/Reviewers: CVPR, ICCV, SIGGRAPH, AAAI, TOG, TIP 
           
                </ul>
           </td>
          </tr>
        </tbody></table>  
                                                                                       
                                                                                   
         <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Selected Awards      </heading>
                <ul>
                  <li> Postgraduate Scholarship, HKUST </li>
                  <li> National Scholarship, Education Ministry  of China </li>
                  <li> Outstanding Student, Beihang University </li>
                  <li> First-Class Scholarship, Beihang University </li>
                  <li> First Prize, The Chinese Mathematics Competitions </li>
                   
                </ul>
           </td>
          </tr>
        </tbody></table>                                                                                       
                                                                                       
                                                                                       
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:center;font-size:small;">Thanks to <a href="https://jonbarron.info/"> Jon Barron</a> for sharing the code of his personal webpage.</p>
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>



<a href="https://www.easycounter.com/">
<img src="https://www.easycounter.com/counter.php?tengfei"
border="0" alt="Hit Counters"></a>
<br><a href="https://www.easycounter.com/">HTML Hit Counters</a>


</html>
