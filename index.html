<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title> Tengfei WANG  </title>
  
  <meta name="author" content="Jon Barron">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Tengfei WANG </name>  <br> <br>
              </p>
              <p style="font-family:verdana"> I am currently a researcher at Tencent Hunyuan, leading a research team on world models. Previously, I was a researcher at Shanghai AI Lab, working closely with <a href="https://liuziwei7.github.io/"> Ziwei Liu </a>. I obtained my PhD degree at the Hong Kong University of Science and Technology (<a href="https://hkust.edu.hk/?cn=1">HKUST</a>), advised by <a href="https://cqf.io">Qifeng Chen</a>. 
                I did research at Microsoft Research Asia (MSRA) from 2021 to 2023.
                <br> I'm interested in AI-based visual content generation, including image, video and 
                3D assets.  I've received HKUST CSE Best PhD Dissertation Award (Honorable Mention) in 2023.
              </p>
 
 
              <p style="text-align:center">
                <a href="mailto:tengfeiwang12@gmail.com"> Email</a> &nbsp/&nbsp
                <a href="https://github.com/Tengfei-Wang"> Github</a> &nbsp/&nbsp 
                <a href="https://scholar.google.com/citations?user=HjpeWKcAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/in/tengfei-wang-836540213/">Linked In</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
             <img style="width:100%;max-width:100%" alt="profile photo" src="images/profile-pic.png" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
                                                                                                                          
                                                                                                                          
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
                <tbody>
                  <tr>
                    <td>
                      <heading>News</heading>
                      <p>
                      <ul>
                        <li>News (Aug  2025): Two papers accepted to SIGGRAPH Asia 2025, including one journal paper.</li>
                        <li>News (Feb  2025): Four papers accepted to CVPR 2025, including two highlight papers.</li>
                        <li>News (Jan  2025): One paper accepted to ICLR 2025.</li>
                        <li>News (Jul  2024): Three papers accepted to ECCV 2024, including one oral paper.</li>
                        <li>News (Apr  2024): One paper accepted to SIGGRAPH 2024.</li>
                        <li>News (Jul  2023): Two papers accepted to ICCV 2023.</li>
                        <li>News (Fed  2023): Two papers accepted to CVPR 2023, including one highlight paper.</li>
                        <li>News (Mar  2022): One paper accepted to CVPR 2022.</li>
                        <li>News (Dec  2021): One paper accepted to AAAI 2022.</li>
                        <li>News (Jul  2021): Two papers accepted to ICCV 2021, including one oral paper.</li>
                        <li>News (Mar 2021): One paper accepted to CVPR 2021.</li>
                        
                      </ul>
                      </p>
                    </td>
                  </tr>
                </tbody>
        </tbody></table>

        <heading>Open-Source Projects</heading>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr onmouseout="lrm_stop()" onmouseover="lrm_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
    
              <div class="one">
                <div class="two" id='lrm_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/openlrm.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/openlrm.jpg' width=100%>
              </div>
              
              <script type="text/javascript">
                function lrm_start() {
                  document.getElementById('lrm_image').style.opacity = "1";
                }

                function lrm_stop() {
                  document.getElementById('lrm_image').style.opacity = "0";
                }
                lrm_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle> OpenLRM: Open-Source Large Reconstruction Models  </papertitle>
            
              <br>
              Zexin He^ and Tengfei Wang
              <br>
              2023
              <br>
              <a href="https://github.com/3DTopia/OpenLRM">code</a> /  
              <a href="https://huggingface.co/spaces/zxhezexin/OpenLRM">online demo</a> /  

              <p></p>
              <p style="color:#d22222"> Fast image-to-3D generating in a few seconds. 
             </p>
            </td>
           </tr>  

          
            <tr onmouseout="dtopia_stop()" onmouseover="dtopia_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='dtopia_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/3dtopia.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/3dtopia.jpg' width=100%>
              </div>
              
              <script type="text/javascript">
                function dtopia_start() {
                  document.getElementById('dtopia_image').style.opacity = "1";
                }

                function dtopia_stop() {
                  document.getElementById('dtopia_image').style.opacity = "0";
                }
                dtopia_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle> 3DTopia: Large Text-to-3D Generation Model  </papertitle>
            
              <br>
             2024
              <br>
              <a href="https://arxiv.org/abs/2403.02234">arxiv</a> /  
              <a href="https://github.com/3DTopia/3DTopia">code</a> /  
              <a href="https://huggingface.co/spaces/hongfz16/3DTopia">online demo</a> /  
              <a href="https://www.youtube.com/watch?v=yybCrfpquFIa">video</a> /  

              <p></p>
              <p style="color:#d22222"> Fast and high-quality text-to-3D generation. 
             </p>
            </td>
           </tr>  



      <tr onmouseout="hyworld1_stop()" onmouseover="hyworld1_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='hyworld1_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/HYWorld.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                
               <video  width=100% height=100% muted autoplay loop>
                <source src="images/HYWorld.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video>
              </div>
              
              <script type="text/javascript">
                function hyworld1_start() {
                  document.getElementById('hyworld1_image').style.opacity = "1";
                }

                function hyworld1_stop() {
                  document.getElementById('hyworld1_image').style.opacity = "0";
                }
                hyworld1_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle> HunyuanWorld 1.0: Generating Immersive, Explorable, and Interactive 3D Worlds from Words or Pixels </papertitle>
            
              <br>
              Project Lead
              <br>
             2025
              <br>
              <a href="https://arxiv.org/abs/2507.21809">arxiv</a> /  
              <a href="https://github.com/Tencent-Hunyuan/HunyuanWorld-1.0">code</a> /  
              <a href="https://3d.hunyuan.tencent.com/sceneTo3D">online demo</a> /  
              <a href="https://3d-models.hunyuan.tencent.com/world/">project page & video</a> /  

              <p></p>
              <p style="color:#d22222"> Immersive and Editable 3D scene generation from images or texts. 
             </p>
            </td>
           </tr>  

  
              <tr onmouseout="hyworld15_stop()" onmouseover="hyworld15_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='hyworld15_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/hyworld1.5.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                
               <video  width=100% height=100% muted autoplay loop>
                <source src="images/hyworld1.5.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video>
              </div>
              
              <script type="text/javascript">
                function hyworld15_start() {
                  document.getElementById('hyworld15_image').style.opacity = "1";
                }

                function hyworld15_stop() {
                  document.getElementById('hyworld15_image').style.opacity = "0";
                }
                hyworld15_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>  HY-World 1.5: A Systematic Framework for Interactive World Modeling with Real-Time Latency and Geometric Consistency </papertitle>
            
              <br>
              Project Lead
              <br>
             2025
              <br>
              <a href="https://3d-models.hunyuan.tencent.com/world/world1_5/HYWorld_1.5_Tech_Report.pdf">arxiv</a> /  
              <a href="https://github.com/Tencent-Hunyuan/HY-WorldPlay">code</a> /  
              <a href="https://3d.hunyuan.tencent.com/sceneTo3D">online demo</a> /  
              <a href="https://3d-models.hunyuan.tencent.com/world/">project page & video</a> /  

              <p></p>
              <p style="color:#d22222"> The first Open-Source world model with real-time latency, long-term memory, interactive control, and long-horizon generation.
             </p>
            </td>
           </tr>  

           </tbody></table>

  
          
        <heading>Publications</heading>
        <p> (*equal contribution, ^intern, &dagger;corresponding author) </p>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

            <tr onmouseout="worldplay_stop()" onmouseover="worldplay_start()">
            <td class="w3-hide-small" style="padding:20px;width:25%;vertical-align:middle">
    
              <div class="one">
                <div class="two" id='worldplay_image'>
                 <video  width=100% height=100% muted autoplay loop>
                <source src="images/worldplay.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video>
             </div>
               <video  width=100% height=100% muted autoplay loop>
                <source src="images/worldplay.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video>
              </div>
              
              <script type="text/javascript">
                function worldplay_start() {
                  document.getElementById('worldplay_image').style.opacity = "1";
                }

                function worldplay_stop() {
                  document.getElementById('worldplay_image').style.opacity = "0";
                }
               worldplay_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle> 	WorldPlay: Towards Long-Term Geometric Consistency for Real-Time Interactive World Modeling  </papertitle>
           
              <br>
              Wenqiang Sun*^, Haiyu Zhang*^, Haoyuan Wang*, Junta Wu, Zehang Wang, Zhenwei Wang, Yunhong Wang, Jun Zhang, <strong> Tengfei Wang<sup>&dagger;</sup> </strong>,  Chunchao Guo
              <br>
              <em> preprint </em>, 2025  
              <br>
              <a href="https://arxiv.org/abs/2512.14614">arxiv</a> / 
              <a href="https://github.com/Tencent-Hunyuan/HY-WorldPlay">code</a> /  
              <a href="https://3d-models.hunyuan.tencent.com/world/">project website</a> /  
              <a href="https://3d.hunyuan.tencent.com/sceneTo3D">online demo</a> /  
       
              <p></p>
              <p style="color:#d22222"> Real-Time World Model with Long-Term Memory.
             </p>
            </td>
          </tr>  




            <tr onmouseout="worldmirror_stop()" onmouseover="worldmirror_start()">
            <td class="w3-hide-small" style="padding:20px;width:25%;vertical-align:middle">
    
              <div class="one">
                <div class="two" id='worldmirror_image'>
                 <video  width=100% height=100% muted autoplay loop>
                <source src="images/WorldMirror.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video>
             </div>
               <video  width=100% height=100% muted autoplay loop>
                <source src="images/WorldMirror.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video>
              </div>
              
              <script type="text/javascript">
                function worldmirror_start() {
                  document.getElementById('worldmirror_image').style.opacity = "1";
                }

                function worldmirror_stop() {
                  document.getElementById('worldmirror_image').style.opacity = "0";
                }
               worldmirror_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle> 	WorldMirror: Universal 3D World Reconstruction with Any-Prior Prompting  </papertitle>
           
              <br>
              Yifan Liu*^, Zhiyuan Min*^, Zhenwei Wang*, Junta Wu, <strong> Tengfei Wang<sup>&dagger;</sup> </strong>, Yixuan Yuan, Yawei Luo, Chunchao Guo
              <br>
              <em> preprint </em>, 2025  
              <br>
              <a href="https://arxiv.org/abs/2510.10726">arxiv</a> / 
              <a href="https://github.com/Tencent-Hunyuan/HunyuanWorld-Mirror">code</a> /  
              <a href="https://3d-models.hunyuan.tencent.com/world/">project website</a> /  
              <a href="https://huggingface.co/spaces/tencent/HunyuanWorld-Mirror">online demo</a> /  
       
              <p></p>
              <p style="color:#d22222"> Universal and Feedforward 3D reconstruction with any input and any output.
             </p>
            </td>
          </tr>  



            <tr onmouseout="flashworld_stop()" onmouseover="flashworldr_start()">
            <td class="w3-hide-small" style="padding:20px;width:25%;vertical-align:middle">
    
              <div class="one">
                <div class="two" id='flashworld_image'>
                 <video  width=100% height=100% muted autoplay loop>
                <source src="images/FlashWorld.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video>
             </div>
               <video  width=100% height=100% muted autoplay loop>
                <source src="images/FlashWorld.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video>
              </div>
              
              <script type="text/javascript">
                function flashworld_start() {
                  document.getElementById('flashworld_image').style.opacity = "1";
                }

                function flashworld_stop() {
                  document.getElementById('flashworld_image').style.opacity = "0";
                }
               flashworld_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle> 	 FlashWorld: High-quality 3D Scene Generation within Seconds  </papertitle>
           
              <br>
              Xinyang Li^,  <strong> Tengfei Wang<sup>&dagger;</sup> </strong>,  Zixiao Gu^, Shengchuan Zhang, Chunchao Guo,  Liujuan Cao
              <br>
              <em> preprint </em>, 2025  
              <br>
              <a href="https://arxiv.org/pdf/2510.13678">arxiv</a> / 
              <a href="https://github.com/imlixinyang/FlashWorld">code</a> /  
              <a href="https://imlixinyang.github.io/FlashWorld-Project-Page/">project website</a> /  
              <a href="https://huggingface.co/spaces/imlixinyang/FlashWorld-Demo-Spark">online demo</a> /  
       
              <p></p>
              <p style="color:#d22222"> Generating 3DGS scenes in 5 seconds on a single GPU.
             </p>
            </td>
          </tr>  


             <tr onmouseout="voyager_stop()" onmouseover="voyager_start()">
            <td class="w3-hide-small" style="padding:20px;width:25%;vertical-align:middle">
    
              <div class="one">
                <div class="two" id='voyager_image'>
                 <video  width=100% height=100% muted autoplay loop>
                <source src="images/voyager.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video>
             </div>
               <video  width=100% height=100% muted autoplay loop>
                <source src="images/voyager.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video>
              </div>
              
              <script type="text/javascript">
                function voyager_start() {
                  document.getElementById('voyager_image').style.opacity = "1";
                }

                function voyager_stop() {
                  document.getElementById('voyager_image').style.opacity = "0";
                }
               voyager_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle> 	Voyager: Long-Range and World-Consistent Video Diffusion for Explorable 3D Scene Generation  </papertitle>
           
              <br>
              Tianyu Huang*^, Guandong Zhengwang*^, <strong> Tengfei Wang<sup>&dagger;</sup> </strong>, Yuhao Liu^, Zhenwei Wang^, Junta Wu, Jie Jiang, Hui Li, Wangmeng Zuo, Chunchao Guo
              <br>
              <em> ACM Transactions on Graphics (SIGGRAPH Asia Journal) </em>, 2025  
              <br>
              <a href="https://arxiv.org/abs/2506.04225">arxiv</a> / 
              <a href="https://github.com/Tencent-Hunyuan/HunyuanWorld-Voyager">code</a> /  
              <a href="https://3d-models.hunyuan.tencent.com/world/">project website</a> /  
       
              <p></p>
              <p style="color:#d22222"> Joint RGB and Depth video generation based on camera control.
             </p>
            </td>
          </tr>  

             <tr onmouseout="sfm_stop()" onmouseover="sfm_start()">
            <td class="w3-hide-small" style="padding:20px;width:25%;vertical-align:middle">
    
              <div class="one">
                <div class="two" id='sfm_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/sfm.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/sfm.jpg' width="100%">
              </div>
              
              <script type="text/javascript">
                function sfm_start() {
                  document.getElementById('sfm_image').style.opacity = "1";
                }

                function sfm_stop() {
                  document.getElementById('sfm_image').style.opacity = "0";
                }
                sfm_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle> Shape-for-Motion: Precise and Consistent Video Editing with 3D Proxy  </papertitle>
           
              <br>
              Yuhao Liu^, <strong> Tengfei Wang<sup>&dagger;</sup> </strong>, Fang Liu, Zhenwei Wang^, Rynson Lau
              <br>
              <em> ACM SIGGRAPH Asia </em>, 2025  
              <br>
              <a href="https://arxiv.org/abs/2506.22432">arxiv</a> / 
              <a href="https://github.com/yuhaoliu7456/Shape-for-Motion">code</a> /  
              <a href="https://shapeformotion.github.io/">project website</a> /  
              <p></p>
              <p style="color:#d22222"> Accurate video editing  with 3D proxy and diffusion rendering.
             </p>
            </td>
          </tr>  

          
           <tr onmouseout="lightrig_stop()" onmouseover="lightrig_start()">
            <td class="w3-hide-small" style="padding:20px;width:25%;vertical-align:middle">
    
              <div class="one">
                <div class="two" id='lightrig_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/lightrig.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/lightrig_before.jpg' width="100%">
              </div>
              
              <script type="text/javascript">
                function lightrig_start() {
                  document.getElementById('lightrig_image').style.opacity = "1";
                }

                function lightrig_stop() {
                  document.getElementById('lightrig_image').style.opacity = "0";
                }
                lightrig_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle> Neural LightRig: Unlocking Accurate Object Normal and Material Estimation with Multi-Light Diffusion  </papertitle>
           
              <br>
              
              Zexin He*^, <strong> Tengfei Wang* </strong>, Xin Huang^, Xingang Pan, Ziwei Liu
              <br>
              <em> CVPR </em>, 2025  
              <br>
              <a href="https://arxiv.org/abs/2412.09593">arxiv</a> / 
              <a href="https://github.com/ZexinHe/Neural-LightRig">code</a> /  
              <a href="https://projects.zxhezexin.com/neural-lightrig/">project website</a> /  
              <a href="https://projects.zxhezexin.com/neural-lightrig/">video</a> /  
              <p></p>
              <p style="color:#d22222"> Accurate single-image inverse rendering with multi-light diffusion as virtual light rigs.
             </p>
            </td>
          </tr>  

                 <tr onmouseout="dtopiaxl_stop()" onmouseover="dtopiaxl_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='dtopiaxl_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/3dtopiaxl.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/3dtopiaxl.jpg' width=100%>
              </div>
              
              <script type="text/javascript">
                function dtopiaxl_start() {
                  document.getElementById('dtopiaxl_image').style.opacity = "1";
                }

                function dtopiaxl_stop() {
                  document.getElementById('dtopiaxl_image').style.opacity = "0";
                }
                dtopiaxl_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle> 3DTopia-XL: High-Quality 3D PBR Asset Generation via Primitive Diffusion  </papertitle>
            
              <br>
             <em> CVPR </em>, 2025  <strong style="color:red">  (Highlight)  </strong>
              <br>
              <a href="https://arxiv.org/abs/2409.12957">arxiv</a> /  
              <a href="https://github.com/3DTopia/3DTopia-XL">code</a> /  
              <a href="https://3dtopia.github.io/3DTopia-XL/">project website</a> /  
              <a href="https://huggingface.co/spaces/FrozenBurning/3DTopia-XL">online demo</a> /  
              <a href="https://www.youtube.com/watch?v=nscGSjrwMDw">video</a> /  

              <p></p>
              <p style="color:#d22222"> 3D DiT with Primirive Representation. 
             </p>
            </td>
           </tr>  
          
           <tr onmouseout="bench3d_stop()" onmouseover="bench3d_start()">
            <td class="w3-hide-small" style="padding:20px;width:25%;vertical-align:middle">
    
              <div class="one">
                <div class="two" id='bench3d_image'>
                  <img src='images/bench3d.png' width="160"></div>
                <img src='images/bench3d.png' width="160">
              </div>
              
              <script type="text/javascript">
                function bench3d_start() {
                  document.getElementById('bench3d_image').style.opacity = "1";
                }

                function bench3d_stop() {
                  document.getElementById('bench3d_image').style.opacity = "0";
                }
                bench3d_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle> 3DGen-Bench: Comprehensive Benchmark Suite for 3D Generative Models  </papertitle>
           
              <br>
              
              Yuhan Zhang^, Mengchen Zhang^, Tong Wu, <strong> Tengfei Wang </strong>, Gordon Wetzstein, Dahua Lin, Ziwei Liu
              <br>
              <em> preprint </em>, 2025  
              <br>
              <a href="https://arxiv.org/pdf/2503.21745">arxiv</a> /   
              <a href="hhttps://huggingface.co/spaces/ZhangYuhan/3DGen-Arena">Arena</a> / 
              <p></p>
              <p style="color:#d22222"> Evaluation models with human preference for 3D generative models.
             </p>
            </td>
          </tr>  

             <tr onmouseout="sar3d_stop()" onmouseover="sar3d_start()">
            <td class="w3-hide-small" style="padding:20px;width:25%;vertical-align:middle">
    
              <div class="one">
                <div class="two" id='sar3d_image'>
                 <video  width=100% height=100% muted autoplay loop>
                <source src="images/SAR3D.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video>
             </div>
               <video  width=100% height=100% muted autoplay loop>
                <source src="images/SAR3D.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video>
              </div>
              
              <script type="text/javascript">
                function sar3d_start() {
                  document.getElementById('sar3d_image').style.opacity = "1";
                }

                function sar3d_stop() {
                  document.getElementById('sar3d_image').style.opacity = "0";
                }
                sar3d_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle> 	SAR3D: Autoregressive 3D Object Generation and Understanding via Multi-scale 3D VQVAE  </papertitle>
           
              <br>
              Yongwei Chen, Yushi Lan, Shangchen Zhou, <strong> Tengfei Wang</strong>, Xingang Pan
              <br>
              <em> CVPR </em>, 2025  
              <br>
              <a href="https://arxiv.org/abs/2411.16856">arxiv</a> / 
              <a href="https://github.com/cyw-3d/SAR3D">code</a> /  
              <a href="https://cyw-3d.github.io/projects/SAR3D/">project website</a> /  
       
              <p></p>
              <p style="color:#d22222"> A 3D auto-regressive model for both 3D generation and understanding.
             </p>
            </td>
          </tr>  
          
           <tr onmouseout="matanything_stop()" onmouseover="matanything_start()">
            <td class="w3-hide-small" style="padding:20px;width:25%;vertical-align:middle">
    
              <div class="one">
                <div class="two" id='matanything_image'>
                  <img src='images/matanything.gif' width="160">
             </div>
                <img src='images/matanything.gif' width="100%">
              </div>
              
              <script type="text/javascript">
                function matanything_start() {
                  document.getElementById('matanything_image').style.opacity = "1";
                }

                function matanything_stop() {
                  document.getElementById('matanything_image').style.opacity = "0";
                }
                matanything_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle> 	Material Anything: Generating Materials for Any 3D Object via Diffusion  </papertitle>
           
              <br>
              Xin Huang^,  <strong> Tengfei Wang<sup>&dagger;</sup> </strong>, Ziwei Liu, Qing Wang
              <br>
              <em> CVPR </em>, 2025  <strong style="color:red">  (Highlight)  </strong>
              <br>
              <a href="https://arxiv.org/abs/2411.15138">arxiv</a> / 
              <a href="https://github.com/3DTopia/MaterialAnything">code</a> /  
              <a href="https://xhuangcv.github.io/MaterialAnything/">project website</a> /  
       
              <p></p>
              <p style="color:#d22222"> A diffusion model generating PBR materials for any 3D mesh.
             </p>
            </td>
          </tr>  
          
            <tr onmouseout="phidias_stop()" onmouseover="phidias_start()">
            <td class="w3-hide-small" style="padding:20px;width:25%;vertical-align:middle">
    
              <div class="one">
                <div class="two" id='phidias_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/phidias.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/phidias.jpg' width="100%">
              </div>
              
              <script type="text/javascript">
                function phidias_start() {
                  document.getElementById('phidias_image').style.opacity = "1";
                }

                function phidias_stop() {
                  document.getElementById('phidias_image').style.opacity = "0";
                }
                phidias_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle> Phidias: A Generative Model for Creating 3D Content from Text, Image, and 3D Conditions with Reference-Augmented Diffusion  </papertitle>
           
              <br>
              Zhenwei Wang*^, <strong> Tengfei Wang*<sup>&dagger;</sup> </strong>, Zexin He^, Gerhard Hancke, Ziwei Liu, Rynson W.H. Lau
              <br>
              <em> ICLR </em>, 2025  
              <br>
              <a href="https://arxiv.org/abs/2409.11406">arxiv</a> / 
              <a href="https://github.com/3DTopia/Phidias-Diffusion">code</a> /  
              <a href="https://rag-3d.github.io/">project website</a> /  
              <a href="https://www.youtube.com/watch?v=MFnHgBWI7Nc">video</a> /  
              <p></p>
              <p style="color:#d22222"> A 3D diffusion model with RAG, supporting 3D generation from text, image, and existing 3D models.
             </p>
            </td>
          </tr>  

        
          
            <tr onmouseout="omni6d_stop()" onmouseover="omni6d_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='omni6d_image'>
                  <img src='images/omni6d_after.jpg' width="160"></div>
                <img src='images/omni6d_before.jpg' width="160">
              </div>
              <script type="text/javascript">
                function omni6d_start() {
                  document.getElementById('omni6d_image').style.opacity = "1";
                }

                function omni6d_stop() {
                  document.getElementById('omni6d_image').style.opacity = "0";
                }
                omni6d_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle> Omni6D: Large-Vocabulary 3D Object Dataset for Category-Level 6D Object Pose Estimation   </papertitle>
            
              <br>
              Mengchen Zhang^, Tong Wu, Tai Wang, <strong> Tengfei Wang </strong>, Ziwei Liu, Dahua Lin
              <br>
              <em> ECCV </em>, 2024   
              <br>
              <a href="https://arxiv.org/abs/2409.18261">arxiv</a> / 
              <a href="https://github.com/3DTopia/Omni6D/">code</a> /  
              <a href="https://www.youtube.com/watch?v=BKyw51bUhZs">video</a> / 
              <a href="https://openxlab.org.cn/datasets/kszpxxzmcwww/Omni6D/">data</a> / 
              <p></p>
              <p style="color:#d22222"> A large and realistic dataset for 6D pose estimation.
             </p>
            </td>
          </tr>      
          
            <tr onmouseout="lgm_stop()" onmouseover="lgm_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
    
              <div class="one">
                <div class="two" id='lgm_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/lgm.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/lgm.jpg' width="160">
              </div>
              
              <script type="text/javascript">
                function lgm_start() {
                  document.getElementById('lgm_image').style.opacity = "1";
                }

                function lgm_stop() {
                  document.getElementById('lgm_image').style.opacity = "0";
                }
                lgm_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle> LGM: Large Multi-View Gaussian Model for High-Resolution 3D Content Creation  </papertitle>
           
              <br>
              Jiaxiang Tang, Zhaoxi Chen, Xiaokang Chen, <strong> Tengfei Wang </strong>, Gang Zeng, Ziwei Liu
              <br>
              <em> ECCV </em>, 2024  <strong style="color:red">  (Oral Presentation,  <a href="https://resources.paperdigest.org/2025/09/most-influential-eccv-papers-2025-09-version/">top5 Influential paper</a>)  </strong>  
              <br>
              <a href="https://arxiv.org/abs/2402.05054">arxiv</a> / 
              <a href="https://github.com/3DTopia/LGM">code</a> /  
              <a href="https://me.kiui.moe/lgm/">project website</a> /  
              <a href="https://huggingface.co/spaces/ashawkey/LGM">online demo</a> /
              <p></p>
              <p style="color:#d22222"> Fast and high-resolution 3D generative model with 3D gaussian splattings. 
             </p>
            </td>
          </tr>  

          
         
          
         <tr onmouseout="comboverse_stop()" onmouseover="comboverse_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='comboverse_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/comboverse.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/comboverse.jpg' width="160">
              </div>
              
              <script type="text/javascript">
                function comboverse_start() {
                  document.getElementById('comboverse_image').style.opacity = "1";
                }

                function comboverse_stop() {
                  document.getElementById('comboverse_image').style.opacity = "0";
                }
                comboverse_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle> ComboVerse: Compositional 3D Assets Creation Using Spatially-Aware Diffusion Guidance  </papertitle>
           
              <br>
              Yongwei Chen*^, <strong> Tengfei Wang*<sup>&dagger;</sup> </strong>, Tong Wu, Xingang Pan, Kui Jia, Ziwei Liu
              <br>
              <em> ECCV </em>, 2024 
              <br>
              <a href="https://arxiv.org/abs/2403.12409">arxiv</a> / 
              <a href="https://cyw-3d.github.io/ComboVerse/">project website</a> /   
              <p></p>
              <p style="color:#d22222"> Image-to-3D for compositional scenes and objects. 
             </p>
            </td>
          </tr>  


             <tr onmouseout="themestation_stop()" onmouseover="themestation_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='themestation_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/themestation.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/themestation.jpg' width="160">
              </div>
              
              <script type="text/javascript">
                function themestation_start() {
                  document.getElementById('themestation_image').style.opacity = "1";
                }

                function themestation_stop() {
                  document.getElementById('themestation_image').style.opacity = "0";
                }
                themestation_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle> ThemeStation : Generating Theme-Aware 3D Assets from Few Exemplars  </papertitle>
           
              <br>
              Zhenwei Wang^, <strong> Tengfei Wang<sup>&dagger;</sup> </strong>, Gerhard Hancke,  Ziwei Liu,  Rynson W.H. Lau
              <br>
              <em> ACM SIGGRAPH </em>, 2024 
              <br>
              <a href="https://arxiv.org/abs/2403.15383">arxiv</a> / 
              <a href="https://github.com/3DTopia/ThemeStation">code</a> /   
              <a href="https://3dthemestation.github.io/">project website</a> /   
              <a href="https://www.youtube.com/watch?v=q6afxQXRl_o">video</a> /
              <p></p>
              <p style="color:#d22222"> Create a gallery of 3D assets with a consistent theme via 3D-to-3D generation. 
             </p>
            </td>
          </tr>  
          
          
            <tr onmouseout="makeit3d_stop()" onmouseover="makeit3d_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
    
              <div class="one">
                <div class="two" id='makeit3d_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/make_it_3d.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/make_it_3d.jpg' width="160">
              </div>
              
              <script type="text/javascript">
                function makeit3d_start() {
                  document.getElementById('makeit3d_image').style.opacity = "1";
                }

                function makeit3d_stop() {
                  document.getElementById('makeit3d_image').style.opacity = "0";
                }
                makeit3d_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle> Make-It-3D: High-Fidelity 3D Creation from A Single Image with Diffusion Prior  </papertitle>
            
              <br>
              Junshu Tang, <strong>  Tengfei Wang </strong>,  Bo Zhang, Ting Zhang, Ran Yi, Lizhuang Ma, Dong Chen 
              <br>
              <em> ICCV </em>, 2023   <strong style="color:red">  ( <a href="https://resources.paperdigest.org/2024/09/most-influential-iccv-papers-2024-09/">top15 Influential paper</a>)  </strong>  
              <br>
              <a href="https://arxiv.org/abs/2303.14184">arxiv</a> / 
              <a href="https://github.com/junshutang/Make-It-3D">code</a> /  
              <a href="https://make-it-3d.github.io/">project website</a> /  
              <a href="https://www.youtube.com/watch?v=2M8JJFeDBFk">video</a> /
              <p></p>
              <p style="color:#d22222"> Generate 3D objects from a single image by distilling 3D knowledge from 2D diffusion model. 
             </p>
            </td>
          </tr>  


            <tr onmouseout="Rodin_stop()" onmouseover="Rodin_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
    
              <div class="one">
                <div class="two" id='Rodin_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/rodin.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/rodin.jpg' width="160">
              </div>
              
              <script type="text/javascript">
                function Rodin_start() {
                  document.getElementById('Rodin_image').style.opacity = "1";
                }

                function Rodin_stop() {
                  document.getElementById('Rodin_image').style.opacity = "0";
                }
                Rodin_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle> RODIN: A Generative Model for Sculpting 3D Digital Avatars Using Diffusion  </papertitle>
            
              <br>
              <strong>  Tengfei Wang </strong>,  Bo Zhang, Ting Zhang, Shuyang Gu,  Jianmin Bao, Tadas Baltrusaitis, Jingjing Shen, Dong Chen, Fang Wen, Qifeng Chen, Baining Guo
              <br>
              <em> CVPR</em>, 2023 <strong style="color:red">  (Highlight, 2.5% acceptance rate)  </strong>
              <br>
              <a href="https://arxiv.org/abs/2212.06135">arxiv</a> / 
              <a href="https://3d-avatar-diffusion.microsoft.com/">code</a> /  
              <a href="https://3d-avatar-diffusion.microsoft.com/">project website</a> /  
              <a href="https://www.youtube.com/watch?v=KW_EXWMjS4c">video</a> /
              <p></p>
              <p style="color:#d22222"> The first 3D diffusion model for generating high-quality 3D digital avatars represented as a neural radiance field. 
             </p>
            </td>
          </tr>  

            <tr onmouseout="SPI_stop()" onmouseover="SPI_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
    
              <div class="one">
                <div class="two" id='SPI_image'>
                  <img src='images/SPI_after.png' width="160"></div>
                <img src='images/SPI_before.png' width="160">
              </div>
              
              <script type="text/javascript">
                function SPI_start() {
                  document.getElementById('SPI_image').style.opacity = "1";
                }

                function SPI_stop() {
                  document.getElementById('SPI_image').style.opacity = "0";
                }
                SPI_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle> 3D GAN Inversion with Facial Symmetry Prior  </papertitle>
             
              <br>
              Fei Yin, Yong Zhang, Xuan Wang, <strong> Tengfei Wang </strong>, Xiaoyu Li, Yuan Gong, Yanbo Fan, Xiaodong Cun, Ying Shan, Cengiz Oztireli, Yujiu Yang
              <br>
              <em> CVPR</em>, 2023   
              <br>
              <a href="https://arxiv.org/pdf/2211.16927">arxiv</a> / 
              <a href="https://github.com/FeiiYin/SPI/">code</a> /  
              <a href="https://feiiyin.github.io/SPI/">project website</a> /  
              <p></p>
              <p style="color:red">   
             </p>
            </td>
          </tr>  

            <tr onmouseout="PITI_stop()" onmouseover="PITI_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='PITI_image'>
                  <img src='images/PITI_after.png' width="160"></div>
                <img src='images/PITI_before.png' width="160">
              </div>
              <script type="text/javascript">
                function PITI_start() {
                  document.getElementById('PITI_image').style.opacity = "1";
                }

                function PITI_stop() {
                  document.getElementById('PITI_image').style.opacity = "0";
                }
                PITI_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle> Pretraining for Image-to-Image Translation  </papertitle>
            
              <br>
              <strong>  Tengfei Wang </strong>, Ting Zhang, Bo Zhang, Hao Ouyang,  Dong Chen, Qifeng Chen, Fang Wen 
              <br>
              <em> technical report</em>, 2022   
              <br>
              <a href="https://arxiv.org/abs/2205.12952">arxiv</a> / 
              <a href="https://github.com/PITI-Synthesis/PITI">code</a> /  
              <a href="https://tengfei-wang.github.io/PITI/index.html">project website</a> / 
              <a href="https://huggingface.co/spaces/tfwang/PITI-Synthesis">online demo</a> / 
              <p></p>
              <p style="color:#d22222"> A simple and universal framework that brings the power of pretraining to various image-to-image translation tasks.
             </p>
            </td>
          </tr>               
          

            <tr onmouseout="hfgi_21_stop()" onmouseover="hfgi_21_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='hfgi_21_image'>
                  <img src='images/hfgi_21_after.gif' width="160"></div>
                <img src='images/hfgi_21_after.gif' width="160">
              </div>
              <script type="text/javascript">
                function hfgi_21_start() {
                  document.getElementById('hfgi_21_image').style.opacity = "1";
                }

                function hfgi_21_stop() {
                  document.getElementById('hfgi_21_image').style.opacity = "0";
                }
                hfgi_21_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle> High-Fidelity GAN Inversion for Image Attribute Editing  </papertitle>
          
              <br>
              <strong>  Tengfei Wang </strong>, Yong Zhang, Yanbo Fan,  Jue Wang, Qifeng Chen 
              <br>
              <em> CVPR </em>, 2022   
              <br>
              <a href="https://arxiv.org/abs/2109.06590">arxiv</a> / 
              <a href="https://github.com/Tengfei-Wang/HFGI">code</a> /  
              <a href="https://tengfei-wang.github.io/HFGI/">project website</a> /
              <a href="https://www.youtube.com/watch?v=_CXk4LjoKP8">video</a> /  
              <a href="https://colab.research.google.com/github/Tengfei-Wang/HFGI/blob/main/HFGI_playground.ipynb">colab</a> / 
              <a href="https://replicate.com/tengfei-wang/hfgi">online demo</a> / 
              <p></p>
              <p style="color:#d22222"> A novel GAN inversion framework for high-fidelity image and video editng.
             </p>
            </td>
          </tr>     

   
     <tr onmouseout="restore_21_stop()" onmouseover="restore_21_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='restore_21_image'>
                  <img src='images/restore_21_after.jpg' width="160"></div>
                <img src='images/restore_21_before.jpg' width="160">
              </div>
              <script type="text/javascript">
                function restore_21_start() {
                  document.getElementById('restore_21_image').style.opacity = "1";
                }

                function restore_21_stop() {
                  document.getElementById('restore_21_image').style.opacity = "0";
                }
                restore_21_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle> Restorable Image Operators with Quasi-Invertible Networks  </papertitle>
           
              <br>
              Hao Ouyang*, <strong>  Tengfei Wang* </strong>, Qifeng Chen 
              <br>
              <em> AAAI </em>, 2022   
              <br>
              <a href="https://www.aaai.org/AAAI22Papers/AAAI-2467.OuyangHao.pdf">arxiv</a> / 
              <a href="https://github.com/ken-ouyang/IVOP">code</a> / 
              <a href="https://tengfei-wang.github.io/Restorable-Image-Operator/">project website</a> /
              <a href="https://www.youtube.com/watch?v=iB7k7jDa9Kg">video</a> /  
              <p></p>
              <p style="color:#d22222"> A general and unified framework for versatile invertible image processing operators.
             </p>       
            </td>
          </tr>     


              <tr onmouseout="sr_iccv21_stop()" onmouseover="sr_iccv21_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='sr_iccv21_image'>
                  <img src='images/sr_iccv21_after.jpg' width="160"></div>
                <img src='images/sr_iccv21_before.jpg' width="160">
              </div>
              <script type="text/javascript">
                function sr_iccv21_start() {
                  document.getElementById('sr_iccv21_image').style.opacity = "1";
                }

                function sr_iccv21_stop() {
                  document.getElementById('sr_iccv21_image').style.opacity = "0";
                }
                sr_iccv21_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle> Dual-Camera Super-Resolution with Aligned Attention Modules  </papertitle>
              
              <br>
              <strong>  Tengfei Wang *</strong>, Jiaxin Xie *, Wenxiu Sun,  Qiong Yan, Qifeng Chen 
              <br>
              <em>ICCV </em>, 2021  <strong style="color:red"> (Oral Presentation, 3.4% acceptance rate)</strong>
              <br>
              <a href="https://arxiv.org/abs/2109.01349">arxiv</a> / 
              <a href="https://github.com/Tengfei-Wang/DCSR">code</a> /  
              <a href="https://tengfei-wang.github.io/Dual-Camera-SR/index.html">project website</a> /
              <a href="https://github.com/Tengfei-Wang/DCSR">dataset</a> /  
              <a href="https://youtu.be/5TiUfAcNvuw">video</a> / 
              <p></p>
              <p style="color:#d22222"> First real-world dual-camera super-resolution approach. <br>
               A new high-quality dataset for dual-camera zoom (telephoto and wide-angle). </p>
            </td>
          </tr>     


          
          
           <tr onmouseout="inpainting_iccv21_stop()" onmouseover="inpainting_iccv21_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='inpainting_iccv21_image'>
                  <img src='images/inpainting_iccv21_after.jpg' width="160"></div>
                <img src='images/inpainting_iccv21_before.jpg' width="160">
              </div>
              <script type="text/javascript">
                function inpainting_iccv21_start() {
                  document.getElementById('inpainting_iccv21_image').style.opacity = "1";
                }

                function inpainting_iccv21_stop() {
                  document.getElementById('inpainting_iccv21_image').style.opacity = "0";
                }
                inpainting_iccv21_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle> Internal Video Inpainting by Implicit Long-range Propagation </papertitle>
            
              <br>
              Hao Ouyang*,  <strong> Tengfei Wang*</strong>,  Qifeng Chen 
              <br>
              <em>ICCV </em>, 2021  
              <br>
              <a href="https://arxiv.org/abs/2108.01912">arxiv</a> / 
              <a href="https://github.com/Tengfei-Wang/Implicit-Internal-Video-Inpainting">code</a> / 
              <a href="https://tengfei-wang.github.io/Implicit-Internal-Video-Inpainting/index.html">project website</a> /
              <a href="https://github.com/Tengfei-Wang/Annotated-4K-Videos">dataset</a> /  
              <a href="https://www.youtube.com/watch?v=VlDSJtmBqBs">video</a> /  
              <p></p>
              <p style="color:#d22222"> A simple yet effective video inpainting method for  videos from arbitrary domains. 
                <br> No training set and pretrained models are needed.  </p>
            </td>
          </tr>           
          
 
          <tr onmouseout="inpainting_cvpr21_stop()" onmouseover="inpainting_cvpr21_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='inpainting_cvpr21_image'>
                  <img src='images/inpainting_cvpr21_after.jpg' width="160"></div>
                <img src='images/inpainting_cvpr21_before.jpg' width="160">
              </div>
              <script type="text/javascript">
                function inpainting_cvpr21_start() {
                  document.getElementById('inpainting_cvpr21_image').style.opacity = "1";
                }

                function inpainting_cvpr21_stop() {
                  document.getElementById('inpainting_cvpr21_image').style.opacity = "0";
                }
                inpainting_cvpr21_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle> Image Inpainting with External-internal Learning and Monochromic Bottleneck  </papertitle>
            
              <br>
              <strong>Tengfei Wang *</strong>, Hao Ouyang *, Qifeng Chen 
              <br>
              <em>CVPR </em>, 2021  
              <br>
              <a href="https://arxiv.org/abs/2104.09068">arxiv</a> / 
              <a href="https://github.com/Tengfei-Wang/external-internal-inpainting">code</a> / 
              <a href="https://tengfei-wang.github.io/EII/index.html">project website</a> /
              <a href="https://youtu.be/JFBEL7qPFVc">video</a> /
              <p></p>
              <p style="color:#d22222"> A novel internal-learning method for guided image colorization  </p>
            </td>
          </tr>  


           
          <tr onmouseout="thesis_stop()" onmouseover="thesis_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='thesis_image'>
                  <img src='images/hkust.jpg' width="160"></div>
                <img src='images/hkust.jpg' width="160">
              </div>
              <script type="text/javascript">
                function thesis_start() {
                  document.getElementById('thesis_image').style.opacity = "1";
                }

                function thesis_stop() {
                  document.getElementById('thesis_image').style.opacity = "0";
                }
                thesis_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle> High-Quality Visual Content Creation with Foundation Generative Models  </papertitle>
            
              <br>
              <strong>Tengfei Wang</strong>
              <br>
              <em>PHD THESIS </em>, 2023 
              <br>
              <a href="https://lbezone.hkust.edu.hk/pdfviewer/web/viewer.php?file=aHR0cHM6Ly9sYmV6b25lLmhrdXN0LmVkdS5oay9vYmovMS9vLzk5MTAxMzIyMjk1NDUwMzQxMi85OTEwMTMyMjI5NTQ1MDM0MTIucGRm#page=1">link</a> / 
               <p style="color:#d22222"> HKUST CSE Best Dissertation Award Honorable Mention
             </p>
            </td>
          </tr>  
          
        </tbody></table>


<!--          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Teaching</heading>
                <ul>
                  <li>Assistant Coach of <a href="https://www.cse.ust.hk/acm/"> HKUST ACM-ICPC Teams </a> (2019 Fall, 2020 Spring, 2020 Fall, 2021 Spring, 2021 Fall) </li>
                  <li>COMP 3071: Honors Competitive Programming</li>          
                </ul>
           </td>
          </tr>
        </tbody></table>  -->

         <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Services</heading>
                <ul>
                  <li> Program Committee/Reviewer: CVPR, ICCV, ECCV, SIGGRAPH, SIGGRAPH Asia, NeurIPS, ICLR, ICML, AAAI, 3DV, TOG, TPAMI, IJCV, TVCG, TIP, TMM </li>
                  <li> Assitant Coach of <a href="https://cse.hkust.edu.hk/acm/" target="_blank">HKUST ACM Team</a> (2019-2023) </li>
                </ul>
           </td>
          </tr>
        </tbody></table>  
                                                                                       
        

   


         <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Selected Awards      </heading>
                <ul>
                  <li> CSE Best PhD Dissertation Award Honorable Mention, HKUST </li>
                  <li> Postgraduate Scholarship, HKUST </li>
                  <li> National Scholarship, Education Ministry  of China </li>
                  <li> Outstanding Student, Beihang University </li>
                  <li> First-Class Scholarship, Beihang University </li>
                   
                </ul>
           </td>
          </tr>
        </tbody></table>                                                                                       
                                                                                       
                                                                                       
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:center;font-size:small;">Thanks to <a href="https://jonbarron.info/"> Jon Barron</a> for sharing the code of his personal webpage.</p>
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>



<a href="https://www.easycounter.com/">
<img src="https://www.easycounter.com/counter.php?tengfei"
border="0" alt="Hit Counters"></a>
<br><a href="https://www.easycounter.com/">HTML Hit Counters</a>


</html>
